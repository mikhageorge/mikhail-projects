# -*- coding: utf-8 -*-
"""Milestone2_ACL2_Mikhail.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11N6Rg0OSUVyP-4mWXNam1_2mLE4GBRe6
"""

# this command crashes when i run it on my Macbook but runs fine on Google colab
# install these packages from teh terminal if you run this code locally
# do not comment tjis line if you will run this code on Google colab
#pip install neo4j pandas

import pandas as pd
from neo4j import GraphDatabase
import time

import pandas as pd
from neo4j import GraphDatabase
import time

# Read the Config file to get knowldege graph details
config = {}
try:
    with open('config.txt', 'r') as file:
        for line in file:
            if '=' in line:
                key, value = line.strip().split('=', 1)
                config[key] = value
except FileNotFoundError:
    print("Error: config.txt not found.")

# Connect to the knowledge graph
uri = config.get('URI')
user = config.get('USERNAME')
password = config.get('PASSWORD')

driver = GraphDatabase.driver(uri, auth=(user, password))

try:
    driver.verify_connectivity()
    print("Cell 1 Complete: Connected to Neo4j successfully!")
except Exception as e:
    print(f"Connection failed: {e}")

# Define the constraints
queries = [
    "CREATE CONSTRAINT traveller_id IF NOT EXISTS FOR (t:Traveller) REQUIRE t.user_id IS UNIQUE",
    "CREATE CONSTRAINT hotel_id IF NOT EXISTS FOR (h:Hotel) REQUIRE h.hotel_id IS UNIQUE",
    "CREATE CONSTRAINT city_name IF NOT EXISTS FOR (c:City) REQUIRE c.name IS UNIQUE",
    "CREATE CONSTRAINT country_name IF NOT EXISTS FOR (k:Country) REQUIRE k.name IS UNIQUE",
    "CREATE CONSTRAINT review_id IF NOT EXISTS FOR (r:Review) REQUIRE r.review_id IS UNIQUE"
]

# Run them
with driver.session() as session:
    for q in queries:
        session.run(q)

print("Cell 2 Complete: Database constraints are active.")

import pandas as pd

print("Reading CSV files...")
hotels_df = pd.read_csv('hotels.csv')
reviews_df = pd.read_csv('reviews.csv')
users_df = pd.read_csv('users.csv')
visa_df = pd.read_csv('visa.csv')

# --- Pre-processing Step ---
# The schema requires 'average_reviews_score' on the Hotel node.
# It is not in the CSV, so we calculate it from reviews.
print("Calculating hotel average scores...")
avg_scores = reviews_df.groupby('hotel_id')['score_overall'].mean().reset_index()
avg_scores.columns = ['hotel_id', 'average_reviews_score']

# Merge the score into the hotels dataframe
hotels_df = pd.merge(hotels_df, avg_scores, on='hotel_id', how='left')
hotels_df['average_reviews_score'] = hotels_df['average_reviews_score'].fillna(0).round(2)

print("Cell 3 Complete: Data loaded and processed in Python.")

hotels_df.head()

with driver.session() as session:

    # 1. Load Countries (Merge from all possible sources)
    print("Loading Countries...")
    all_countries = set(hotels_df['country']) | set(users_df['country']) | set(visa_df['from']) | set(visa_df['to'])
    country_batch = [{'name': c} for c in all_countries if pd.notna(c)]
    session.run("""
    UNWIND $batch AS row
    MERGE (:Country {name: row.name})
    """, batch=country_batch)

    # 2. Load Cities & Connect to Country
    print("Loading Cities...")
    city_batch = hotels_df[['city', 'country']].drop_duplicates().to_dict('records')
    session.run("""
    UNWIND $batch AS row
    MERGE (c:City {name: row.city})
    WITH c, row
    MATCH (k:Country {name: row.country})
    MERGE (c)-[:LOCATED_IN]->(k)
    """, batch=city_batch)

    # 3. Load Hotels & Connect to City
    print("Loading Hotels...")
    hotel_batch = hotels_df.to_dict('records')
    session.run("""
    UNWIND $batch AS row
    MERGE (h:Hotel {hotel_id: row.hotel_id})
    SET h.name = row.hotel_name,
        h.star_rating = row.star_rating,
        h.cleanliness_base = row.cleanliness_base,
        h.comfort_base = row.comfort_base,
        h.facilities_base = row.facilities_base,
        h.average_reviews_score = row.average_reviews_score

    WITH h, row
    MATCH (c:City {name: row.city})
    MERGE (h)-[:LOCATED_IN]->(c)
    """, batch=hotel_batch)

    # 4. Load Travellers & Connect to Country
    # Schema Mapping: age_group -> age, traveller_type -> type, user_gender -> gender
    print("Loading Travellers...")
    user_batch = users_df.to_dict('records')
    session.run("""
    UNWIND $batch AS row
    MERGE (t:Traveller {user_id: row.user_id})
    SET t.age = row.age_group,
        t.type = row.traveller_type,
        t.gender = row.user_gender

    WITH t, row
    MATCH (k:Country {name: row.country})
    MERGE (t)-[:FROM_COUNTRY]->(k)
    """, batch=user_batch)

print("Cell 4 Complete: Entities and location links created.")

"""in the previous code ,
relation traveller from country was created
relation hotel located in city was created
relation city located in country was created
"""

print("Loading Reviews (this may take 1-2 minutes)...")

# Convert dataframe to a list of dictionaries
review_batch = reviews_df.to_dict('records')

# Process in chunks of 5000 to avoid memory errors
batch_size = 5000

with driver.session() as session:
    for i in range(0, len(review_batch), batch_size):
        chunk = review_batch[i:i + batch_size]

        session.run("""
        UNWIND $batch AS row
        MERGE (r:Review {review_id: row.review_id})
        SET r.text = row.review_text,
            r.date = row.review_date,
            r.score_overall = row.score_overall,
            r.score_cleanliness = row.score_cleanliness,
            r.score_comfort = row.score_comfort,
            r.score_facilities = row.score_facilities,
            r.score_location = row.score_location,
            r.score_staff = row.score_staff,
            r.score_value_for_money = row.score_value_for_money

        // Link Review -> Hotel
        WITH r, row
        MATCH (h:Hotel {hotel_id: row.hotel_id})
        MERGE (r)-[:REVIEWED]->(h)

        // Link Traveller -> Review
        WITH r, h, row
        MATCH (t:Traveller {user_id: row.user_id})
        MERGE (t)-[:WROTE]->(r)

        // Link Traveller -> Hotel (STAYED_AT)
        MERGE (t)-[:STAYED_AT]->(h)
        """, batch=chunk)

        print(f"   -> Processed {i + len(chunk)} / {len(review_batch)} reviews")

print("Cell 5 Complete: All reviews loaded and linked.")

print("Loading Visa Requirements...")

# Filter: We only care if requires_visa is "Yes"
# The schema says: (Country)-[:NEEDS_VISA]->(Country)
# We strictly follow the schema rule to include the 'visa_type' property.
visa_required = visa_df[visa_df['requires_visa'] == 'Yes'].to_dict('records')

with driver.session() as session:
    session.run("""
    UNWIND $batch AS row
    MATCH (c1:Country {name: row.from})
    MATCH (c2:Country {name: row.to})
    MERGE (c1)-[:NEEDS_VISA {visa_type: row.visa_type}]->(c2)
    """, batch=visa_required)

print("Cell 6 Complete: Visa rules applied.")
print("The graph is complete.")

# Close connection
driver.close()

"""the previous part handeled creating the knowledge graph

"""

from neo4j import GraphDatabase

# --- Re-Connect to Database ---
# (We need to re-open the driver because it was closed in the last cell)
config = {}
with open('config.txt', 'r') as file:
    for line in file:
        line = line.strip()
        if '=' in line and not line.startswith('#'):
            key, value = line.split('=', 1)
            config[key.strip()] = value.strip()

driver = GraphDatabase.driver(config['URI'], auth=(config['USERNAME'], config['PASSWORD']))

print("--- VERIFICATION PHASE (Updated) ---")

with driver.session() as session:

    # ---------------------------------------------------------
    # Q1: Travellers visiting countries without visa needs
    # (Includes domestic travel). Target Answer: 1999
    # ---------------------------------------------------------
    q1 = """
    MATCH (t:Traveller)-[:STAYED_AT]->(h:Hotel)-[:LOCATED_IN]->(c:City)-[:LOCATED_IN]->(visit:Country)
    MATCH (t)-[:FROM_COUNTRY]->(home:Country)
    WHERE home.name = visit.name OR NOT (home)-[:NEEDS_VISA]->(visit)
    RETURN count(DISTINCT t) as traveler_count
    """
    result1 = session.run(q1).single()['traveler_count']
    print(f"\n1. Travellers without visa issues (Target: 1999): {result1}")
    if result1 == 1999:
        print("The answer matches the solution given")
    else:
        print(f"MISMATCH! Got {result1}. (Check Visa logic)")

    # ---------------------------------------------------------
    # Q2: Top 3 hotels with highest avg ratings for Business travellers
    # ---------------------------------------------------------
    q2 = """
    MATCH (t:Traveller {type: 'Business'})-[:WROTE]->(r:Review)-[:REVIEWED]->(h:Hotel)
    RETURN h.name, avg(r.score_overall) as rating
    ORDER BY rating DESC LIMIT 3
    """
    print("\n2. Top 3 Hotels for Business Travellers:")
    for record in session.run(q2):
        print(f"   - {record['h.name']}: {record['rating']:}")

    # ---------------------------------------------------------
    # Q3: Count of couple travellers per hotel (ALL Hotels)
    # ---------------------------------------------------------
    q3 = """
    MATCH (h:Hotel)
    OPTIONAL MATCH (t:Traveller {type: 'Couple'})-[:STAYED_AT]->(h)
    RETURN h.name, count(t) as couple_count
    ORDER BY h.name ASC
    """
    print("\n3. Couple Travellers per Hotel (Full List):")
    for record in session.run(q3):
        print(f"   - {record['h.name']}: {record['couple_count']}")

    # ---------------------------------------------------------
    # Q4: Top 3 hotels with avg cleanliness < 8.8
    # ---------------------------------------------------------
    q4 = """
    MATCH (r:Review)-[:REVIEWED]->(h:Hotel)
    WITH h, avg(r.score_cleanliness) as avg_clean
    WHERE avg_clean < 8.8
    RETURN h.name, avg_clean
    ORDER BY avg_clean ASC LIMIT 3
    """
    print("\n4. Hotels with Cleanliness < 8.8 (Top 3 Worst):")
    for record in session.run(q4):
        print(f"   - {record['h.name']}: {record['avg_clean']:}")

    # ---------------------------------------------------------
    # Q5: Hotels with highest location scores for women
    # ---------------------------------------------------------
    q5 = """
    MATCH (t:Traveller {gender: 'Female'})-[:WROTE]->(r:Review)-[:REVIEWED]->(h:Hotel)
    WITH h, avg(r.score_location) as loc_score
    WITH max(loc_score) as max_score
    MATCH (t:Traveller {gender: 'Female'})-[:WROTE]->(r:Review)-[:REVIEWED]->(h:Hotel)
    WITH h, avg(r.score_location) as loc_score, max_score
    WHERE loc_score = max_score
    RETURN h.name, loc_score
    """
    print("\n5. Best Location Score for Women:")
    for record in session.run(q5):
        print(f"   - {record['h.name']}: {record['loc_score']:}")

"""the previous part handeled testing the queries and seeing if we get teh same results as the solution given to us .
As can be seen , the results obtained are the same as the ones given to us
"""

print("--- Calculating 'Exceeds Expectations' Rule ---")

query = """
MATCH (t:Traveller {type: 'Solo', gender: 'Female'})-[:WROTE]->(r:Review)-[:REVIEWED]->(h:Hotel)
WITH t.age AS age_group,
     h,
     (h.cleanliness_base + h.comfort_base + h.facilities_base) AS base_score,
     avg(r.score_cleanliness + r.score_comfort + r.score_facilities) AS review_score

// Condition: Hotel exceeds expectations (Base >= Review)
WHERE base_score >= review_score

// Calculate Improvement Percentage
WITH age_group,
     h,
     ((base_score - review_score) / review_score) * 100 AS improvement_pct

// Aggregation per demographic
RETURN age_group,
       min(improvement_pct) AS min_improvement_pct,
       max(improvement_pct) AS max_improvement_pct,
       avg(improvement_pct) AS avg_improvement_pct
ORDER BY age_group
"""

with driver.session() as session:
    result = session.run(query)
    data = [dict(record) for record in result]

# Display as a clean table using Pandas
df_results = pd.DataFrame(data)

if not df_results.empty:
    # Round to 2 decimal places to match your answer key
    cols = ['min_improvement_pct', 'max_improvement_pct', 'avg_improvement_pct']
    df_results[cols] = df_results[cols].round(2)

    print("\nRESULTS TABLE:")
    print(df_results.to_string(index=False))
else:
    print("No data found matching the criteria.")

"""The previous part is about the rule .
what can be seen that the results obtaned as the results given to us .
"""